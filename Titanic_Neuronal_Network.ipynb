{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronales Netzwerk für den Titanic Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.5)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (1.5.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\alexa\\anaconda3\\envs\\alex\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install pandas\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\anaconda3\\envs\\Alex\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6530 - loss: 0.6364 - val_accuracy: 0.6993 - val_loss: 0.6087\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 0.5603 - val_accuracy: 0.7203 - val_loss: 0.5754\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7347 - loss: 0.5297 - val_accuracy: 0.7552 - val_loss: 0.5500\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4891 - val_accuracy: 0.7622 - val_loss: 0.5317\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.4769 - val_accuracy: 0.7902 - val_loss: 0.5152\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.4277 - val_accuracy: 0.7902 - val_loss: 0.5031\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4313 - val_accuracy: 0.8112 - val_loss: 0.4949\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.4204 - val_accuracy: 0.8112 - val_loss: 0.4846\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.4363 - val_accuracy: 0.8182 - val_loss: 0.4847\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.4274 - val_accuracy: 0.8112 - val_loss: 0.4819\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4487 - val_accuracy: 0.8042 - val_loss: 0.4789\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.4196 - val_accuracy: 0.8182 - val_loss: 0.4797\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.4040 - val_accuracy: 0.8042 - val_loss: 0.4789\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.3917 - val_accuracy: 0.8182 - val_loss: 0.4771\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4012 - val_accuracy: 0.8182 - val_loss: 0.4785\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3612 - val_accuracy: 0.8182 - val_loss: 0.4804\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.3917 - val_accuracy: 0.8182 - val_loss: 0.4780\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.3447 - val_accuracy: 0.8252 - val_loss: 0.4769\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.3561 - val_accuracy: 0.8112 - val_loss: 0.4790\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3934 - val_accuracy: 0.8112 - val_loss: 0.4836\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8561 - loss: 0.3538 - val_accuracy: 0.8042 - val_loss: 0.4902\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3614 - val_accuracy: 0.8042 - val_loss: 0.4844\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.3753 - val_accuracy: 0.7972 - val_loss: 0.4833\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3618 - val_accuracy: 0.8042 - val_loss: 0.4896\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3817 - val_accuracy: 0.7972 - val_loss: 0.4852\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.3246 - val_accuracy: 0.8112 - val_loss: 0.4935\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.4029 - val_accuracy: 0.7972 - val_loss: 0.4914\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.3367 - val_accuracy: 0.8042 - val_loss: 0.4916\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3422 - val_accuracy: 0.7972 - val_loss: 0.4905\n",
      "Epoch 30/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.3211 - val_accuracy: 0.7972 - val_loss: 0.4918\n",
      "Epoch 31/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3408 - val_accuracy: 0.7902 - val_loss: 0.4965\n",
      "Epoch 32/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3468 - val_accuracy: 0.7972 - val_loss: 0.4918\n",
      "Epoch 33/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3470 - val_accuracy: 0.7902 - val_loss: 0.4942\n",
      "Epoch 34/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.3217 - val_accuracy: 0.7902 - val_loss: 0.4946\n",
      "Epoch 35/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.3127 - val_accuracy: 0.7902 - val_loss: 0.4985\n",
      "Epoch 36/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3634 - val_accuracy: 0.7972 - val_loss: 0.4959\n",
      "Epoch 37/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3256 - val_accuracy: 0.7902 - val_loss: 0.5006\n",
      "Epoch 38/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8635 - loss: 0.3569 - val_accuracy: 0.7902 - val_loss: 0.5029\n",
      "Epoch 39/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3062 - val_accuracy: 0.7902 - val_loss: 0.4971\n",
      "Epoch 40/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3655 - val_accuracy: 0.7902 - val_loss: 0.4962\n",
      "Epoch 41/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.3253 - val_accuracy: 0.7902 - val_loss: 0.5044\n",
      "Epoch 42/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3451 - val_accuracy: 0.7902 - val_loss: 0.4983\n",
      "Epoch 43/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.3638 - val_accuracy: 0.7832 - val_loss: 0.4964\n",
      "Epoch 44/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.3153 - val_accuracy: 0.7902 - val_loss: 0.5060\n",
      "Epoch 45/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.3766 - val_accuracy: 0.7832 - val_loss: 0.5024\n",
      "Epoch 46/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.3255 - val_accuracy: 0.7902 - val_loss: 0.5069\n",
      "Epoch 47/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8830 - loss: 0.3349 - val_accuracy: 0.7902 - val_loss: 0.5122\n",
      "Epoch 48/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.3296 - val_accuracy: 0.7902 - val_loss: 0.5079\n",
      "Epoch 49/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.3467 - val_accuracy: 0.7902 - val_loss: 0.5080\n",
      "Epoch 50/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3061 - val_accuracy: 0.7902 - val_loss: 0.5075\n",
      "Validierungsgenauigkeit: 79.02%\n"
     ]
    }
   ],
   "source": [
    "# Importieren der notwendigen Bibliotheken\n",
    "import pandas as pd  # Pandas wird verwendet, um Daten zu laden und zu bearbeiten\n",
    "from sklearn.model_selection import train_test_split  # Methode zum Aufteilen der Daten in Trainings- und Testsets\n",
    "from sklearn.preprocessing import StandardScaler  # Methode zur Skalierung von Daten (Normalisierung)\n",
    "from tensorflow.keras.models import Sequential  # Importiert das Sequential-Modell von Keras (für den Aufbau eines neuronalen Netzwerks)\n",
    "from tensorflow.keras.layers import Dense  # Importiert die Dense-Schicht (voll verbundene Schicht) von Keras\n",
    "from tensorflow.keras.utils import to_categorical  # Hilfsfunktion zur Umwandlung von Zielvariablen in eine kategorische Form\n",
    "\n",
    "# Laden der Titanic-Daten\n",
    "df_titanic_train = pd.read_csv('titanic_training.csv')  # Daten werden aus einer CSV-Datei in ein Pandas DataFrame geladen\n",
    "\n",
    "# Datenvorverarbeitung\n",
    "X = df_titanic_train.drop(['Survived', 'Cabin', 'Ticket', 'Name'], axis=1)  # Unnötige Spalten (Zielvariable und andere) werden aus den Eingabedaten entfernt\n",
    "y = df_titanic_train['Survived']  # Zielvariable \"Survived\" wird extrahiert\n",
    "\n",
    "# Umwandlung kategorischer Variablen\n",
    "X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})  # Geschlechtsvariable wird in numerische Werte umgewandelt (0 für männlich, 1 für weiblich)\n",
    "X['Embarked'] = X['Embarked'].map({'Q': 0, 'S': 1, 'C': 2})  # Embarkationsvariable wird in numerische Werte umgewandelt (0 für Q, 1 für S, 2 für C)\n",
    "\n",
    "# Entfernen von fehlenden Werten\n",
    "X.dropna(inplace=True)  # Alle Zeilen mit fehlenden Werten in den Eingabedaten werden entfernt\n",
    "y = y[X.index]  # Die Zielvariable wird entsprechend den verbleibenden Indizes der Eingabedaten angepasst\n",
    "\n",
    "# Aufteilen der Daten in Trainings- und Validierungsdatensätze\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "# Daten werden in Trainings- (80%) und Validierungssätze (20%) aufgeteilt, der random_state sorgt für Reproduzierbarkeit\n",
    "\n",
    "# Skalieren der Daten\n",
    "scaler = StandardScaler()  # Initialisieren eines StandardSkalierers zur Normalisierung der Daten\n",
    "X_train = scaler.fit_transform(X_train)  # Der Skalierer wird auf die Trainingsdaten angepasst und diese werden transformiert (Mittelwert = 0, Standardabweichung = 1)\n",
    "X_val = scaler.transform(X_val)  # Der Skalierer wird verwendet, um die Validierungsdaten mit denselben Parametern zu transformieren\n",
    "\n",
    "# Umwandlung der Zielvariablen in kategorische Daten (für ein neuronales Netzwerk)\n",
    "y_train = to_categorical(y_train, num_classes=2)  # Die Zielvariable wird in eine One-Hot-kodierte Form umgewandelt (zwei Klassen: Überlebt oder nicht)\n",
    "y_val = to_categorical(y_val, num_classes=2)  # Dasselbe wird mit den Validierungsdaten gemacht\n",
    "\n",
    "# Erstellen des neuronalen Netzwerks\n",
    "model = Sequential()  # Initialisieren eines Sequential-Modells (eine lineare Stapelung von Schichten)\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Erste Dense-Schicht mit 32 Neuronen und ReLU-Aktivierung, die Eingabedimension ist die Anzahl der Merkmale\n",
    "model.add(Dense(16, activation='relu'))  # Zweite Dense-Schicht mit 16 Neuronen und ReLU-Aktivierung\n",
    "model.add(Dense(2, activation='softmax'))  # Ausgabeschicht mit 2 Neuronen und Softmax-Aktivierung für Klassifikation in zwei Klassen\n",
    "\n",
    "# Kompilieren des Modells\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "# Das Modell wird kompiliert, wobei der Verlust als kategorische Kreuzentropie verwendet wird, der Optimierer ist Adam, und die Genauigkeit wird als Metrik verwendet\n",
    "\n",
    "# Training des Modells\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)  \n",
    "# Das Modell wird mit den Trainingsdaten trainiert, über 50 Epochen und einer Batch-Größe von 32, und die Validierungsdaten werden nach jeder Epoche verwendet, um die Leistung zu überprüfen\n",
    "\n",
    "# Auswertung des Modells\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)  # Das Modell wird auf den Validierungsdaten ausgewertet, um Verlust und Genauigkeit zu berechnen\n",
    "\n",
    "print(f\"Validierungsgenauigkeit: {accuracy*100:.2f}%\")  # Die Genauigkeit des Modells auf den Validierungsdaten wird in Prozent ausgegeben\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
